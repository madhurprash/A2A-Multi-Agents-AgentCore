general:
  name: "ops-orchestrator-agent"      
  description: ""

# This contains the model information for various agents
# in our multi agentic system
agent_information:
  # Represents the system prompt templates for each agent
  prompt_templates:
    prompt_template_dir: prompt_template
    # This is the system prompt for the monitoring agent that will be used 
    # in agent creation and development
    ops_orchestrator_agent:
  ops_orchestrator_agent_model_info: 
    # Represents the model id that the agent will use within 
    # the strands agents SDK
    model_id: gpt-4o-2024-08-06
    # Represents the inference parameters that the foundation model
    # uses at runtime during inference
    inference_parameters:
      # This is not an exhaustive list, it can be changed or extended
      # based on the inference parameters that are supported
      temperature: 0.1
      max_tokens: 2048
    # There are memories for all of the agents that will be used in this sample
    # there are three agents with different memory storage strategies and all will be used
    memories:
      lead_agent:
        use_existing: true
        memory_id: OpsAgent_mem_1753364538-TvqIKh3jxd
      chat_ops_agent:
        use_existing: true
        memory_id: OpsAgent_chat_1753364705-2bbQkyHyVO
      ticket_agent:
        use_existing: true
        memory_id: TicketCreation_chat_1753364881-Dq80O2DlHQ
    memory_credentials:
      # fetch this from your AWS console
      id: 
    memory_allocation:
      # An actor refers to an entity such as an end user or an agent that interacts with the
      # agent application. For example, in a coding use case, an actor is a developer asking
      # questions to the assistant. Using the actor id helps the system know which user the 
      # memory belongs to, keeping each user's data separate and organized
      actor_id: actor_agent_openAI_madhur2039
      # The session is usually a single conversation that is the interaction period between
      # the user and the AI agent
      # A namespace is used to logically group and organize the long term memories, these will
      # be created on the fly using the strategies that are used in the memory for the agent.
    # GATEWAY CONFIGURATION FOR THE MONITORING AGENT
    # Gateway configuration for the monitoring agent
    # Gateway configuration with Keycloak
    gateway_config:
      name: "ops-gw"
      # Cognito authentication configuration
      inbound_auth:
        type: "cognito"
        cognito:
          create_user_pool: true
          user_pool_name: "agentcore-gateway-ops-new"
          resource_server_id: "ops_orchestrator_agent"
          resource_server_name: "agentcore-gateway-ops"
          client_name: "agentcore-client-ops"
          scopes:
            - ScopeName: "gateway:read"
              ScopeDescription: "Read access"
            - ScopeName: "gateway:write"
              ScopeDescription: "Write access"
      credentials:
        use_cognito: true        # must be a YAML boolean
        use_existing: false
        create_new_access_token: false
        gateway_id: null
        mcp_url: null
        access_token: null
      
      # Gateway targets configuration
      existing_target: false
      target_name: null
      bucket_name: "ops-orchestrator-gateway-bucket"
      
      # Target configurations
      targets:
        - name: "jira-integration-new"
          # Absolute path to your openAPI spec file
          spec_file: /Users/madhurpt/Desktop/genesis/multi-agents/ops_orchestrator_agent/tools/jira_api_spec.yaml
          type: "openapi"
          api_type: "jira"
          endpoint: "https://your-jira-instance.atlassian.net"
          authentication:
            type: "basic"
            credentials:
              username: "${JIRA_USERNAME}"
              password: "${JIRA_API_TOKEN}"
        
        # - name: "slack-integration"
        #   type: "openapi"
        #   endpoint: "https://slack.com/api"
        #   authentication:
        #     type: "bearer"
        #     credentials:
        #       token: "${SLACK_BOT_TOKEN}"
        
        - name: "github-integration-new"
          # Absolute path to your openAPI spec file
          spec_file: /Users/madhurpt/Desktop/genesis/multi-agents/ops_orchestrator_agent/tools/github_api_spec.yaml
          type: "openapi"
          api_type: "github"
          endpoint: "https://api.github.com"
          authentication:
            type: "bearer"
            credentials:
              token: "${GITHUB_TOKEN}"
              
      # this is the name of the bucket where the target files (openapi or smithy) will
      # be uploaded from
      bucket_name: fmbench-deep-dive
      # this is the description of the agent gateway
      description: "AgentCore Gateway for the openAI operations agent"
      # protocol type is MCP
      protocol_type: "MCP"
      # These can be MCP servers that are local or available through streamable http or sse
      # We will be fetching tools from these MCP servers and then use that behind a tool gateway
      # This tool gateway will ultimately contain local tools and MCP server tools that will be available
      # as endpoints to call through the tool gateway primitive
      # These can be json files for now are supported, can be lambda functions as well
      # This represents the target type for the gateway
      existing_target: true
      target_name: OpsTarget
      target_type: openapi
      # IAM Role Configuration
      # this is the IAM role that will be attached to this gateway
      iam_role:
        execution_role_arn: "arn:aws:iam::ACCOUNT_ID:role/GenesisGatewayExecutionRole"
      # This is if the agent is already configured and needs to be invokeds
      agent_arn: 
      # set this to false if the agent arn is provided from above
      launch_agentcore_runtime: true
      # this is the runtime execution role for the agent that will be used 
      runtime_exec_role: arn:aws:iam::218208277580:role/service-role/Amazon-Bedrock-IAM-Role-20240102T112809